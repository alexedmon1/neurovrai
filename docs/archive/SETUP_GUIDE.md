# Complete Setup and Usage Guide

This guide shows you how to properly set up and run the pipeline **without using Claude**.

## Initial Setup (One Time)

### 1. Install uv (if not already installed)

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### 2. Clone/Navigate to Repository

```bash
cd /home/edm9fd/sandbox/human-mri-preprocess
```

### 3. Sync Dependencies

This installs all required packages into `.venv/`:

```bash
uv sync
```

**What this does:**
- Reads `pyproject.toml` for dependencies
- Creates/updates `.venv/` with all packages
- Updates `uv.lock` with exact versions
- Installs: nipype, DIPY, TEDANA, AMICO, nibabel, etc.

**You should see:**
```
Resolved 103 packages
Installed X packages
```

### 4. Verify Installation

Check that key packages are installed:

```bash
uv pip list | grep -E "nipype|dipy|amico|tedana|nibabel"
```

**Expected output:**
```
dmri-amico        2.1.0
dipy              1.11.0
nibabel           5.3.2
nipype            1.10.0
tedana            25.0.1
```

## Running the Pipeline

You have **two options** for running Python scripts:

### Option 1: Using `uv run` (Recommended)

Run scripts directly without activating the virtual environment:

```bash
# Single subject
uv run python run_simple_pipeline.py \
    --subject IRC805-0580101 \
    --dicom-dir /mnt/bytopia/IRC805/raw/dicom/IRC805-0580101 \
    --config config.yaml

# Batch processing
uv run python run_batch_simple.py --config config.yaml
```

**Advantages:**
- No need to activate venv
- Always uses correct environment
- Works from any directory

### Option 2: Activate Virtual Environment

Activate once, then run multiple commands:

```bash
# Activate the virtual environment
source .venv/bin/activate

# Now you can run scripts directly
python run_simple_pipeline.py \
    --subject IRC805-0580101 \
    --dicom-dir /path/to/dicom \
    --config config.yaml

# Run another script
python run_batch_simple.py --config config.yaml

# When done, deactivate
deactivate
```

**Advantages:**
- Faster for multiple commands
- Traditional workflow
- Can use regular `python` and `pip`

## Complete Workflow Example

### Step 1: Initial Setup (First Time Only)

```bash
cd /home/edm9fd/sandbox/human-mri-preprocess
uv sync
```

### Step 2: Test on Single Subject

```bash
# Create logs directory
mkdir -p logs

# Test run
uv run python run_simple_pipeline.py \
    --subject IRC805-0580101 \
    --dicom-dir /mnt/bytopia/IRC805/raw/dicom/IRC805-0580101 \
    --config config.yaml
```

### Step 3: Monitor Progress

In another terminal:

```bash
# Watch log file
tail -f logs/simple_pipeline.log
```

### Step 4: Run Batch (if single subject succeeded)

```bash
uv run python run_batch_simple.py --config config.yaml
```

## Troubleshooting

### Issue: "ModuleNotFoundError: No module named 'amico'"

**Cause:** Dependencies not installed or wrong Python environment

**Solution:**
```bash
# Re-sync dependencies
uv sync

# Verify AMICO is installed
uv pip list | grep amico

# Should show: dmri-amico  2.1.0
```

### Issue: "uv: command not found"

**Cause:** uv not installed or not in PATH

**Solution:**
```bash
# Install uv
curl -LsSf https://astral.sh/uv/install.sh | sh

# Add to PATH (add to ~/.bashrc for permanent)
export PATH="$HOME/.local/bin:$PATH"
```

### Issue: Old packages from previous installation

**Cause:** Stale `.venv/` from before dependencies were fixed

**Solution:**
```bash
# Remove old virtual environment
rm -rf .venv

# Recreate with correct dependencies
uv sync
```

### Issue: "Configuration validation failed"

**Cause:** Missing or incorrect `config.yaml`

**Solution:**
```bash
# Verify config exists
ls -la config.yaml

# Check project_dir is correct
grep project_dir config.yaml
```

## Adding New Dependencies

If you need to add a new package:

```bash
# Add to pyproject.toml dependencies list, then:
uv sync

# Or install directly (also updates pyproject.toml)
uv add package-name
```

## Environment Management

### View Installed Packages

```bash
uv pip list
```

### Check Specific Package

```bash
uv pip show nipype
```

### Update Dependencies

```bash
# Update all packages to latest compatible versions
uv sync --upgrade
```

### Lock File

The `uv.lock` file ensures reproducible environments:
- **Commit it to git** for consistency
- **Don't edit manually**
- Regenerated by `uv sync`

## Directory Checklist

Before running, ensure these exist:

```bash
# Required directories
ls -ld /mnt/bytopia/IRC805/raw/dicom/
ls -ld /home/edm9fd/sandbox/human-mri-preprocess/logs/

# Config file
ls -la config.yaml
```

## Quick Reference

### Daily Use Commands

```bash
# Single subject (most common)
uv run python run_simple_pipeline.py \
    --subject SUBJECT_ID \
    --dicom-dir /path/to/dicom \
    --config config.yaml

# Batch all subjects
uv run python run_batch_simple.py --config config.yaml

# Batch specific subjects
uv run python run_batch_simple.py \
    --config config.yaml \
    --subjects SUB1 SUB2 SUB3

# Skip modalities
uv run python run_simple_pipeline.py \
    --subject SUBJECT_ID \
    --dicom-dir /path/to/dicom \
    --config config.yaml \
    --skip-func --skip-asl
```

### Maintenance Commands

```bash
# Update environment
uv sync

# Clean old work files
rm -rf /mnt/bytopia/IRC805/work/*

# View logs
tail -f logs/simple_pipeline.log
```

## FSL/FreeSurfer Environment

The pipeline requires FSL and optionally FreeSurfer:

```bash
# Ensure FSL is loaded
echo $FSLDIR  # Should show /usr/local/fsl or similar

# If not loaded
module load fsl

# Or source directly
source /usr/local/fsl/etc/fslconf/fsl.sh
```

## Performance Tips

### GPU Acceleration

DWI preprocessing uses GPU if available:

```bash
# Check CUDA availability
nvidia-smi

# Load CUDA module if needed
module load cuda
```

### Parallel Processing

The simple pipeline runs sequentially, but workflows internally use parallel processing:

- Nipype workflows: Set `n_procs` in `config.yaml`
- Default: 6 cores

```yaml
execution:
  plugin: MultiProc
  n_procs: 6  # Adjust based on your system
```

## Getting Help

### Check Pipeline Status

```bash
# View current processes
ps aux | grep python

# Disk usage
df -h /mnt/bytopia/IRC805/

# Check outputs
ls -lh /mnt/bytopia/IRC805/derivatives/SUBJECT_ID/
```

### Debug Mode

For more verbose output:

```bash
# Set logging level to DEBUG
export NIPYPE_LOG_LEVEL=DEBUG

uv run python run_simple_pipeline.py ...
```

## Summary: Best Practices

1. ✅ **Always use `uv run`** for consistency
2. ✅ **Run `uv sync`** after pulling code changes
3. ✅ **Test single subject** before batch
4. ✅ **Monitor logs** during execution
5. ✅ **Clean work directory** periodically
6. ✅ **Check FSL is loaded** before starting
7. ✅ **Verify config.yaml** paths are correct

## Need More Help?

- Check logs: `logs/simple_pipeline.log`
- View Nipype working files: `/mnt/bytopia/IRC805/work/{subject}/`
- Check QC outputs: `/mnt/bytopia/IRC805/qc/{subject}/`
- Review documentation: `SIMPLE_PIPELINE_GUIDE.md`
